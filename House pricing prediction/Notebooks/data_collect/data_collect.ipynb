{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import urllib.request\r\n",
    "import re\r\n",
    "import csv\r\n",
    "\r\n",
    "def crawl_page(url=''):\r\n",
    "    page= urllib.request.urlopen(url)\r\n",
    "    soup_page= BeautifulSoup(page,'html.parser')\r\n",
    "    return soup_page\r\n",
    "\r\n",
    "def write_csv(line=[], file=''):\r\n",
    "    with open(file, 'a', newline='') as csvfile:\r\n",
    "        spamwriter = csv.writer(csvfile, delimiter=' ',\r\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\r\n",
    "        spamwriter.writerow(line)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataCollect():\r\n",
    "    def __init__(self):\r\n",
    "        self.__url_to_open='https://www.property24.com'\r\n",
    "        self.__soup=crawl_page(self.__url_to_open)\r\n",
    "        self.__area_url=[]\r\n",
    "        self.__list_url=[]\r\n",
    "        self.__property_url=[]\r\n",
    "    \r\n",
    "    def collect_all_first_page_url(self):\r\n",
    "        other_links= self.__soup.find('div',class_='p24_popular').find(class_='col-8').find_all('a',class_='p24_bold')\r\n",
    "        for link in other_links:\r\n",
    "            self.__area_url.append(self.__url_to_open+link.get('href'))\r\n",
    "        first_element_tag= self.__soup.find('div',class_='p24_popular').find(class_='col-8').find_all(class_='row')[1]\r\n",
    "        first_link=first_element_tag.find('a').get('href')\r\n",
    "        temp_soup= crawl_page(self.__url_to_open+first_link)\r\n",
    "        parent_link= temp_soup.find(id='breadCrumbContainer').find_all('a')[1]\r\n",
    "        self.__area_url.append(self.__url_to_open+parent_link.get('href'))\r\n",
    "    \r\n",
    "    def collect_all_url(self):\r\n",
    "        self.collect_all_first_page_url()\r\n",
    "        for link in self.__area_url:\r\n",
    "            soup= crawl_page(link)\r\n",
    "            link_house_tag= soup.find('ul',class_='p24_relatedSales').find(href=re.compile(\"houses-for-sale\")).get('href')\r\n",
    "            link_apart_tag= soup.find('ul',class_='p24_relatedSales').find(href=re.compile(\"apartments-for-sale\")).get('href')\r\n",
    "            link_townhouse_tag= soup.find('ul',class_='p24_relatedSales').find(href=re.compile(\"townhouses-for-sale\")).get('href')\r\n",
    "            self.__list_url.append(link_house_tag)\r\n",
    "            self.__list_url.append(link_apart_tag)\r\n",
    "            self.__list_url.append(link_townhouse_tag)\r\n",
    "\r\n",
    "    def get_property_data(self, link=''):\r\n",
    "        prop_soup= crawl_page(link)\r\n",
    "        \r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "    def get_property_url(self):\r\n",
    "        self.collect_all_url()\r\n",
    "        for link in self.__list_url:\r\n",
    "            soup= crawl_page(self.__url_to_open+link)\r\n",
    "            pagination= soup.find('div',class_='p24_pager').find_all('li')[-1].find('a').get('data-pagenumber')\r\n",
    "            page_number= int(pagination)\r\n",
    "            cur_soup=soup\r\n",
    "            number_properties=0\r\n",
    "            print(link)\r\n",
    "            for page in range(1, page_number+1):\r\n",
    "                print(page)\r\n",
    "                properties= cur_soup.find_all('div',class_='js_resultTile')\r\n",
    "                for prop_index in range(len(properties)-1):\r\n",
    "                    prop_link= properties[prop_index].find('a').get('href')\r\n",
    "                    write_csv([prop_link],'properties_url.csv')\r\n",
    "                number_properties+= len(properties)\r\n",
    "                next_button=cur_soup.find('div',class_='p24_pager').find('a', class_='pull-right').get('href')\r\n",
    "                print(next_button)\r\n",
    "                cur_soup= crawl_page(next_button)\r\n",
    "            print(number_properties)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dc= DataCollect()\r\n",
    "dc.get_property_url()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deepai': conda)"
  },
  "interpreter": {
   "hash": "b54b66dfa7cdbe8a69b3bf148d9797a1fcee399928c1f348c50707ec239ca9b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}