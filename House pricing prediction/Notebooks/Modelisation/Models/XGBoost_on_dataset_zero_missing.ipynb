{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import xgboost as xgb\r\n",
    "from sklearn import linear_model\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import r2_score\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.ensemble import GradientBoostingRegressor\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.svm import SVR\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "data = pd.read_csv(\"../../../Data/Dataset_zero_numeric_missing.csv\",sep=\";\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get feature categories"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def categorisation(data,target=\"price\"):\r\n",
    "    distance = []\r\n",
    "    numerique = []\r\n",
    "    categorique = []\r\n",
    "    for col in data.columns:\r\n",
    "        if data[col].dtypes == np.object:\r\n",
    "            try:\r\n",
    "                if str(type(eval(data[col][data[col].first_valid_index()]))) == \"<class 'list'>\":\r\n",
    "                    distance.append(col)\r\n",
    "                else:\r\n",
    "                    categorique.append(col)\r\n",
    "            except:\r\n",
    "                categorique.append(col)\r\n",
    "                \r\n",
    "            \r\n",
    "        else :\r\n",
    "            if col != target:\r\n",
    "                numerique.append(col)\r\n",
    "                \r\n",
    "    return dict({\"numerique\":numerique,\"categorique\":categorique,\"distance\":distance})\r\n",
    "\r\n",
    "feat_cat = categorisation(data)\r\n",
    "\r\n",
    "feat_cat"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_4648/3923361036.py:6: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data[col].dtypes == np.object:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'numerique': ['bathrooms', 'bedrooms', 'sampling'],\n",
       " 'categorique': ['name', 'province', 'city', 'address', 'type_of_property'],\n",
       " 'distance': ['education', 'transport_and_public_services']}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropping name, address and city because there is high cardinality (cf EDA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "data= data.drop(['name','address','city'],axis=1)\r\n",
    "data.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['price', 'province', 'type_of_property', 'bathrooms', 'bedrooms',\n",
       "       'education', 'transport_and_public_services', 'sampling'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform distance features to lenght of list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "class transfo_distance:\r\n",
    "    def __init__(self,data,features=None):\r\n",
    "        self.data = data\r\n",
    "        self.method = None\r\n",
    "        ### Get features\r\n",
    "        self.distance=[]\r\n",
    "        if features is None:\r\n",
    "            for col in data.columns:\r\n",
    "                if data[col].dtypes == np.object:\r\n",
    "                    try:\r\n",
    "                        if str(type(eval(data[col][data[col].first_valid_index()]))) == \"<class 'list'>\":\r\n",
    "                            self.distance.append(col)\r\n",
    "                    except:\r\n",
    "                        pass\r\n",
    "        else:\r\n",
    "            distance=features\r\n",
    "        \r\n",
    "        ###Transformations : \"mean\", \"median\", \"max\", \"min\", \"len\"\r\n",
    "    def transformation(self,method):\r\n",
    "        self.method = method\r\n",
    "        for feat in self.distance:\r\n",
    "            serie = []\r\n",
    "            for i in data[feat]:\r\n",
    "                if str(i) != \"nan\":\r\n",
    "                    serie.append(self.checker(i))\r\n",
    "                else :\r\n",
    "                    serie.append(np.nan)\r\n",
    "            self.data[feat] = serie\r\n",
    "            \r\n",
    "    def checker(self,value):\r\n",
    "        if self.method==\"mean\":\r\n",
    "            return (np.array(eval(value))).mean()\r\n",
    "        elif self.method ==\"median\":\r\n",
    "            return (np.array(eval(value))).mediane()\r\n",
    "        elif self.method ==\"min\":\r\n",
    "            return (np.array(eval(value))).min()\r\n",
    "        elif self.method ==\"max\":\r\n",
    "            return (np.array(eval(value))).max()\r\n",
    "        elif self.method ==\"len\":\r\n",
    "            return float(len(eval(value)))\r\n",
    "        else:\r\n",
    "            raise('choose correct method : \"mean\", \"median\", \"max\", \"min\", \"len\"')\r\n",
    "    \r\n",
    "    def get_data(self,method=\"mean\"):\r\n",
    "        self.transformation(method)\r\n",
    "        return self.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "trans_dist = transfo_distance(data)\r\n",
    "data = trans_dist.get_data(method=\"len\")\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_4648/2201901570.py:9: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data[col].dtypes == np.object:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9445, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data= data[~(data['type_of_property'] == 'Vacant Land / Plot')]\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9444, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding cadegorical data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using LabelEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def label_encoding(data,labels):\r\n",
    "    for label in labels:\r\n",
    "        label_encoder= LabelEncoder()\r\n",
    "        data[label]=label_encoder.fit_transform(data[label])\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using dummies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def using_dummies(data):\r\n",
    "    return pd.get_dummies(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using custom label encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def label_custom_encoding(data,labels):\r\n",
    "    for label in labels:\r\n",
    "        values= data[label].unique()\r\n",
    "        for value in values:\r\n",
    "            code= len(data[data[label]==value])\r\n",
    "            data.loc[data[label]==value,label]=int(code)\r\n",
    "        data[label]=pd.to_numeric(data[label])\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### target mean ordering encoding of categorical value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def encode(frame, feature):\r\n",
    "    ordering = pd.DataFrame()\r\n",
    "    ordering['val'] = frame[feature].unique()\r\n",
    "    ordering.index = ordering.val\r\n",
    "    ordering['spmean'] = frame[[feature, 'price']].groupby(feature).mean()['price']\r\n",
    "    #print(frame[[feature, 'a']].groupby(feature).mean()['a'])\r\n",
    "    ordering = ordering.sort_values('spmean')\r\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\r\n",
    "    #print(ordering)\r\n",
    "    ordering = ordering['ordering'].to_dict()\r\n",
    "    #print(ordering)\r\n",
    "    \r\n",
    "    for cat, o in ordering.items():\r\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# data= using_dummies(data)\r\n",
    "\r\n",
    "qual_encoded = []\r\n",
    "feat_cat = categorisation(data)\r\n",
    "for q in feat_cat[\"categorique\"]:  \r\n",
    "    encode(data, q)\r\n",
    "    qual_encoded.append(q+'_E')\r\n",
    "print(qual_encoded)\r\n",
    "\r\n",
    "\r\n",
    "# data= label_custom_encoding(data,feat_cat['categorique'])\r\n",
    "\r\n",
    "# data= label_encoding(data,feat_cat['categorique'])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['province_E', 'type_of_property_E']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_4648/3923361036.py:6: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data[col].dtypes == np.object:\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\deepai\\lib\\site-packages\\pandas\\core\\indexing.py:1684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\deepai\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def split_data(data,target,col=\"sampling\",features_to_keep=None):\r\n",
    "    if features_to_keep is not None :\r\n",
    "        features_to_keep = features_to_keep + [target]\r\n",
    "        data = data[features_to_keep]\r\n",
    "        \r\n",
    "    unique = data[\"sampling\"].unique()\r\n",
    "    for i, v in enumerate(unique):\r\n",
    "        if v == 1 :\r\n",
    "            data_train = data[data[col]==v]\r\n",
    "            y_train = data_train[target]\r\n",
    "            X_train = data_train.drop([target,\"sampling\"],axis=1)\r\n",
    "            print(\"train shape :\",X_train.shape)\r\n",
    "        elif v == 2 :\r\n",
    "            data_val = data[data[col]==v]\r\n",
    "            y_val = data_val[target]\r\n",
    "            X_val = data_val.drop([target,\"sampling\"],axis=1)\r\n",
    "            print(\"val shape :\",X_val.shape)\r\n",
    "        elif v == 3 :\r\n",
    "            data_test = data[data[col]==v]\r\n",
    "            y_test = data_test[target]\r\n",
    "            X_test = data_test.drop([target,\"sampling\"],axis=1)\r\n",
    "            print(\"test shape :\",X_test.shape)\r\n",
    "    \r\n",
    "            \r\n",
    "    return X_train, np.log(y_train), X_val, np.log(y_val), X_test, np.log(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "feats_to_keep =[ 'bathrooms', 'bedrooms', 'education',\r\n",
    "       'transport_and_public_services', 'province_E','sampling','type_of_property_E']\r\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(data,\"price\",features_to_keep=feats_to_keep)\r\n",
    "# X_train, y_train, X_val, y_val, X_test, y_test = split_data(data,\"price\")\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train shape : (6571, 6)\n",
      "val shape : (1465, 6)\n",
      "test shape : (1408, 6)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9444, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "reg = xgb.XGBRegressor(n_jobs=2)\r\n",
    "reg.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=2, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "y_prediction =  reg.predict(X_val)\r\n",
    "y_prediction"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\deepai\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([12.967912, 14.465218, 14.601284, ..., 14.248821, 15.149316,\n",
       "       14.229378], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_val, reg.predict(X_val)))\r\n",
    "print(\"The Root mean squared error (RMSE) on val set: {:.4f}\".format(rmse))\r\n",
    "rmse = np.sqrt(mean_squared_error(y_train, reg.predict(X_train)))\r\n",
    "print(\"The Root mean squared error (RMSE) on train set: {:.4f}\".format(rmse))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Root mean squared error (RMSE) on val set: 0.4346\n",
      "The Root mean squared error (RMSE) on train set: 0.3330\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\deepai\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "print(\"Model : RF\")\r\n",
    "\r\n",
    "RF = RandomForestRegressor()\r\n",
    "RF.fit(X_train, y_train)\r\n",
    "\r\n",
    "rmse = np.sqrt(mean_squared_error(y_val, RF.predict(X_val)))\r\n",
    "print(\"The Root mean squared error (RMSE) on val set: {:.4f}\".format(rmse))\r\n",
    "rmse = np.sqrt(mean_squared_error(y_train, RF.predict(X_train)))\r\n",
    "print(\"The Root mean squared error (RMSE) on train set: {:.4f}\".format(rmse))\r\n",
    "\r\n",
    "print(\"Model : RidgeCV\")\r\n",
    "\r\n",
    "regCV = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\r\n",
    "regCV.fit(X_train, y_train)\r\n",
    "\r\n",
    "rmse = np.sqrt(mean_squared_error(y_val, regCV.predict(X_val)))\r\n",
    "print(\"The Root mean squared error (RMSE) on val set: {:.4f}\".format(rmse))\r\n",
    "rmse = np.sqrt(mean_squared_error(y_train, regCV.predict(X_train)))\r\n",
    "print(\"The Root mean squared error (RMSE) on train set: {:.4f}\".format(rmse))\r\n",
    "\r\n",
    "print(\"Model : SVR\")\r\n",
    "\r\n",
    "regr = SVR(C=1.0,epsilon=0.2)\r\n",
    "regr.fit(X_train, y_train)\r\n",
    "\r\n",
    "rmse = np.sqrt(mean_squared_error(y_val, regr.predict(X_val)))\r\n",
    "print(\"The Root mean squared error (RMSE) on val set: {:.4f}\".format(rmse))\r\n",
    "rmse = np.sqrt(mean_squared_error(y_train, regr.predict(X_train)))\r\n",
    "print(\"The Root mean squared error (RMSE) on train set: {:.4f}\".format(rmse))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model : RF\n",
      "The Root mean squared error (RMSE) on val set: 0.4480\n",
      "The Root mean squared error (RMSE) on train set: 0.2525\n",
      "Model : RidgeCV\n",
      "The Root mean squared error (RMSE) on val set: 0.5054\n",
      "The Root mean squared error (RMSE) on train set: 0.5283\n",
      "Model : SVR\n",
      "The Root mean squared error (RMSE) on val set: 0.4576\n",
      "The Root mean squared error (RMSE) on train set: 0.4744\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deepai': conda)"
  },
  "interpreter": {
   "hash": "b54b66dfa7cdbe8a69b3bf148d9797a1fcee399928c1f348c50707ec239ca9b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}